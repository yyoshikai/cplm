{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, csv, math, random, itertools, pickle, logging, yaml, psutil\n",
    "from collections import defaultdict\n",
    "import concurrent.futures as cf\n",
    "from tqdm import tqdm\n",
    "from addict import Dict\n",
    "import numpy as np, pandas as pd\n",
    "sys.path.append('/workspace')\n",
    "from tools.logger import add_stream_handler, get_logger\n",
    "sys.path.append(\"/workspace/cplm\")\n",
    "from src.utils.lmdb import new_lmdb\n",
    "from src.data.lmdb import npy_to_lmdb\n",
    "logger = get_logger()\n",
    "add_stream_handler(logger, logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重い\n",
    "import cudf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  241216 finetune dataの分割(crossdockedの分割に従う)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/cplm/preprocess/results/finetune/r4/filenames.csv\"\n",
    "dffile = pd.read_csv(filepath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(len(dffile))\n",
    "dffile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 条件をstrにまとめる。\n",
    "conds = []\n",
    "for dname, lname, pname, sdf_idx in zip(tqdm(dffile['dname']), dffile['lig_name'], dffile['protein_name'], dffile['sdf_idx']):\n",
    "    sdf_idx = str(sdf_idx)\n",
    "    cond = '/'.join([dname, lname, pname, sdf_idx])\n",
    "    conds.append(cond)\n",
    "conds = np.array(conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検索しやすいようにdictにする。\n",
    "cond2i = {cond: i for i, cond in enumerate(conds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レコードがuniqueであるか確認...OK\n",
    "uconds = np.unique(conds)\n",
    "print(len(conds), len(uconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfftest = pd.read_csv(\"/workspace/cheminfodata/crossdocked/types/cdonly_it2_tt_v1.3_0_test0.types\", sep=' ', header=None)\n",
    "dfftrain = pd.read_csv(\"/workspace/cheminfodata/crossdocked/types/cdonly_it2_tt_v1.3_0_train0.types\", sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "print(len(dfftest))\n",
    "print(dfftest[4][:5].tolist())\n",
    "dfftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認\n",
    "dfftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dffileに対し, dftrain, dftestに含まれているものを探す。\n",
    "nofile_conds = {}\n",
    "cond_counts = {}\n",
    "for split, dff in zip(['test', 'train'], [dfftest, dfftrain]):\n",
    "    nofile_conds[split] = []\n",
    "    cond_counts[split] = np.zeros(len(conds), dtype=int)\n",
    "    for idx, rec, lig in zip(dff.index, tqdm(dff[3]), dff[4]):\n",
    "        rec_dir, rec_base = rec.split('/')\n",
    "        lig_dir, lig_base = lig.split('/')\n",
    "        assert rec_dir == lig_dir, idx\n",
    "        rec_base, rec_ext = os.path.splitext(rec_base)\n",
    "        lig_base, lig_ext = os.path.splitext(lig_base)\n",
    "        assert rec_ext == lig_ext == '.gninatypes', idx\n",
    "        rec_base, rec_idx = rec_base.rsplit('_', maxsplit=1)\n",
    "        assert rec_idx == '0', idx\n",
    "        protein_name = rec_base+'.pdb'\n",
    "        lig_name, sdf_idx = lig_base.rsplit('_', maxsplit=1)\n",
    "        lig_name = lig_name+'.sdf'\n",
    "        cond = '/'.join([rec_dir, lig_name, protein_name, sdf_idx])\n",
    "        if cond in cond2i:\n",
    "            cond_counts[split][cond2i[cond]]+=1\n",
    "        else:\n",
    "            nofile_conds[split].append(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# どのようなものがないのか\n",
    "print(len(nofile_conds['train']))\n",
    "print(nofile_conds['train'][0])\n",
    "# ... 普通にこれらのファイルはあった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dffile[dffile['dname'] == \"1433B_HUMAN_1_240_pep_0\"]\n",
    "print(len(dft))\n",
    "dft\n",
    "# ..._it1_が入っているものは取っていないようだった。なんで？\n",
    "# 確かにコード上もそうなってた。 ... そういえばBindGPTにminとdockedだけ使うと書いてあった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BindGPTはどれを使っているか分からないので, 数を調べる。\n",
    "# BindGPTは27Mくらいだった。...少ない。\n",
    "sys.path.append(\"/workspace/cplm\")\n",
    "from src.utils.lmdb import load_lmdb\n",
    "env, txn = load_lmdb(\"/workspace/cplm/preprocess/results/finetune/r4/main.lmdb\")\n",
    "print(env.stat()['entries'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 241218 cd2020のtypesファイルに基づいてr4_allを分割\n",
    "データ容量削減のため, lmdbに保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv(\"/workspace/cplm/preprocess/results/finetune/r4_all/filenames.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "dftype_train = cudf.read_csv(f\"/workspace/cheminfodata/crossdocked/types/it2_tt_v1.3_0_train{seed}.types\", \n",
    "    header=None, names=['label', 'pK', 'RMSD', 'Receptor', 'Ligand', 'Vina score'], sep=' ')\n",
    "dftype_test = cudf.read_csv(f\"/workspace/cheminfodata/crossdocked/types/it2_tt_v1.3_0_test{seed}.types\",\n",
    "    header=None, names=['label', 'pK', 'RMSD', 'Receptor', 'Ligand', 'Vina score'], sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnames_train = {receptor.split('/')[0] for receptor in dftype_train['Receptor'].to_pandas()}\n",
    "dnames_test = {receptor.split('/')[0] for receptor in dftype_test['Receptor'].to_pandas()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1835/1835 [00:17<00:00, 107.22it/s]\n",
      "100%|██████████| 1065/1065 [00:09<00:00, 111.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29517648 14263936 1528868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split = np.full(len(df), fill_value=-1, dtype=int)\n",
    "df['split'] = -1\n",
    "for dname in tqdm(dnames_train):\n",
    "    df['split'][df['dname'] == dname] = 0\n",
    "for dname in tqdm(dnames_test):\n",
    "    df['split'][df['dname'] == dname] = 1\n",
    "\n",
    "print((df['split'] == 0).sum(), (df['split'] == 1).sum(), (df['split']==-1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0\", exist_ok=True)\n",
    "train_idx = df.index[df['split'] == 0].to_pandas().values\n",
    "test_idx = df.index[df['split'] == 1].to_pandas().values\n",
    "np.save(f\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/train_idxs.npy\", train_idx)\n",
    "np.save(f\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_idxs.npy\", test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29517648/29517648 [01:46<00:00, 276880.32it/s]\n"
     ]
    }
   ],
   "source": [
    "input = \"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/train_idxs.npy\"\n",
    "output = \"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/train_idxs.lmdb\"\n",
    "\n",
    "# input = \"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_idxs.npy\"\n",
    "# output = \"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_idxs.lmdb\"\n",
    "\n",
    "index = np.load(input)\n",
    "env, txn = new_lmdb(output)\n",
    "for i, idx in enumerate(tqdm(index)):\n",
    "    txn.put(str(i).encode('ascii'), pickle.dumps(idx))\n",
    "txn.commit()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29517648/29517648 [00:13<00:00, 2252027.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# 250524 npy_to_lmdbに変更\n",
    "npy_to_lmdb(\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/train_idxs.npy\")\n",
    "npy_to_lmdb(\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_idxs.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 250524 生成の評価用に, 各ディレクトリから1つずつサンプリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/workspace/cplm/preprocess/results/finetune/r4_all/filenames.csv.gz\")\n",
    "test_idxs = np.load(\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_idxs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45310452 14263936\n"
     ]
    }
   ],
   "source": [
    "print(len(df), len(test_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1054/1054 [01:19<00:00, 13.26it/s]\n"
     ]
    }
   ],
   "source": [
    "dnames = df['dname'].values[test_idxs]\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "udnames = np.unique(dnames)\n",
    "rng.shuffle(udnames)\n",
    "\n",
    "iidxs = []\n",
    "for dname in tqdm(udnames):\n",
    "    dname_iidxs = np.where(dnames == dname)[0]\n",
    "    iidxs.append(rng.choice(dname_iidxs))\n",
    "\n",
    "idxs = test_idxs[iidxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_dirwise_idxs.npy\", np.array(idxs, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054\n",
      "1054\n"
     ]
    }
   ],
   "source": [
    "# 確認\n",
    "print(len(idxs))\n",
    "dnames = df['dname'].values[idxs]\n",
    "print(len(set(dnames.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1054/1054 [00:00<00:00, 590305.30it/s]\n"
     ]
    }
   ],
   "source": [
    "npy_to_lmdb(\"/workspace/cplm/preprocess/results/finetune/r4_all/split/it2_0/test_dirwise_idxs.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "241",
   "language": "python",
   "name": "241"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
